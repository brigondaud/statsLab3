---
title: "Report - LDA Lab"
author: "Jose Munoz Angulo, Vivien Marcault, Baptiste Rigondaud"
date: "March 19, 2018"
output: html_document
---

```{r, echo=FALSE}
library("class")
library("MASS")

NAm2 = read.table("NAm2.txt", header=TRUE)

cont <- function(x)
{
  if (x %in% c("Canada"))
      cont<-"NorthAmerica"
  else if (x %in% c("Guatemala","Mexico","Panama","CostaRica"))
      cont<-"CentralAmerica"
  else
      cont<-"SouthAmerica"
  return (factor(cont))
}
contID<-sapply(as.character(NAm2[,4]),FUN=cont)
```

## Question a)

Creation of the labels:

```{r}
labels<-rep(1: 2, each=494/2)
set=sample(labels, 494)
```

Creation of the table that contains the continent of origin and the genetic markers:

```{r}
NAcont<-cbind(contID=contID,NAm2[,-(1:8)])
NAcont[,1]<-factor(NAcont[,1])
```

Computation of the lda:

```{r}

#lda(contID~., data=NAcont, subset=(set==1)) Does not work
```

Since some predictors seem to be constant in some classes (zero-variance), the computation of the LDA won't be possible. In fact, since the equality of the covariances is assumed, //TODO: continue

## Question b)

In order to peform such operation, we use the code below:

```{r}
withinvar<-apply(NAcont[(set==1),-1],FUN=function(x){tapply(x,NAcont[(set==1),1],FUN=var)},MARGIN=2)
bool<-as.logical(apply(withinvar,FUN=function(x){prod(x!=0)},MARGIN=2))
NAcont2<-cbind(contID=contID,(NAm2[,-(1:8)])[,bool])
NAcont2[,1]<-factor(NAcont[,1])

#Count the number of remaining markers
count <- length(NAcont2[1,])-1
```
The number of remaining markers is `count`. The markers that were removed from the model have a variance of zero for at least one continent. This means that there are markers that do not yield information since they are constant for every continent. Thus, there are not relevant for the model. However, since some of the markers that were removed are constant for only one continent, some information is lost.

In order to learn the model, we run:
```{r, echo=FALSE, warning=FALSE}
model=lda(contID~., data=NAcont2, subset=(set==1))
```
```{r, eval=FALSE}
lda(contID~., data=NAcont2, subset=(set==1))
```

## Question c)

In order to predict the original populations of individuals who have not been trained, we use the following code:

```{r}
pre = predict(model, newdata=subset(NAcont[, -1], set==2),type="class")
pre$class
```

## Question d)

Computation of the confusion matrix:

```{r}
confusion = table(subset(NAcont[, 1], set==2), pre$class)
barplot(confusion, legend.text=TRUE)
```

From this representation of the confusion matrix we can see that there are non-negligible errors that have been made during the prediction. Our hypothesis is that the South American and Central American populations might have been more in contact with one another, thus mixing the gene pool and having more genetic traits in common. While the North American population genes remained untouched.

## Question e)

In order to compute the prediction error, we calculate by subtracting the number
of well predicted values, i.e., the sum of the diagonal in the confusion matrix
to the total number of samples used in the validation phase. This is the total
value of mismatched samples. We divide the number of samples to the previously
obtained value to calculate the mismatching ratio.

```{r}
error <- (sum(confusion) - sum(diag(confusion)))/sum(confusion)
error
```

## Question f)
```{r, echo=FALSE}
set = function(N, k) {
  r <- floor(N / k) # Number of values for each fold.
  miss <- N - k * r # Missing values.
  
  t <- c(rep(r, times = k)) # Number of samples in each fold.
  t <- t + sample(rep(0:1, times = c(miss, k - miss))) # Add missing values
  
  sample(rep(1:k, times = t)) # Set selection vector
}
```
```{r, warning=FALSE}
# K-fold cross validation.
k <- 10 # Number of folds
set <- set(494, k) # Set selection vector.
errors <- c()

for (i in 1:k) {
  # Remove markers
  withinvar<-apply(NAcont[(set!=i),-1],FUN=function(x){tapply(x,NAcont[(set!=i),1],FUN=var)},MARGIN=2)
  bool<-as.logical(apply(withinvar,FUN=function(x){prod(x!=0)},MARGIN=2))
  NAcont2<-cbind(contID=contID,(NAm2[,-(1:8)])[,bool])
  NAcont2[,1]<-factor(NAcont[,1])
  
  # Generate model
  model <- lda(contID~., data=NAcont2, subset=(set!=i))
  
  # Predict values
  pre <- predict(model, newdata=subset(NAcont[, -1], set == i),type="class")
  
  # Calculate error
  confusion <- table(subset(NAcont[, 1], set == i), pre$class)
  errors <- c(errors, (sum(confusion) - sum(diag(confusion)))/sum(confusion))
}

print(errors)
```
// Proposé: avoir autant d'individus pour l'apprentissage --> éviter de biaiser pour une population sur-représentée --> prendre un set plus intelligement. Prendre la population la moinsn représentée, tu la divises par deux, une partie part dans set1 et l'autre set2 et équilibrer le reste en fonction